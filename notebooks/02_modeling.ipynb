{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mod√©lisation - Syst√®me de Recommandation MovieLens\n",
    "\n",
    "**Auteur:** Dady Akrou Cyrille  \n",
    "**Email:** cyrilledady0501@gmail.com  \n",
    "**Date:** D√©cembre 2024\n",
    "\n",
    "Ce notebook impl√©mente et teste diff√©rents mod√®les de recommandation :\n",
    "- Filtrage collaboratif (SVD, NMF, KNN)\n",
    "- Filtrage par contenu (TF-IDF, Genres)\n",
    "- Syst√®mes hybrides (Weighted, Switching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports n√©cessaires\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Ajouter le r√©pertoire src au path\n",
    "sys.path.append(str(Path('../src').resolve()))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "import yaml\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Imports des modules personnalis√©s\n",
    "from data_processing.preprocess import MovieLensPreprocessor\n",
    "from models.collaborative_filtering import CollaborativeFilteringManager\n",
    "from models.content_based_filtering import ContentBasedManager\n",
    "from models.hybrid_system import HybridSystemManager\n",
    "from evaluation.metrics import ModelEvaluator\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Configuration des graphiques\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"‚úÖ Imports r√©alis√©s avec succ√®s!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement de la configuration\n",
    "config_path = Path('../config/config.yaml')\n",
    "\n",
    "with open(config_path, 'r', encoding='utf-8') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "print(\"Configuration charg√©e:\")\n",
    "print(f\"- Chemin des donn√©es: {config['data']['base_path']}\")\n",
    "print(f\"- Mod√®les √† tester: {len(config['models'])} types\")\n",
    "print(f\"- M√©triques d'√©valuation: {len(config['evaluation']['metrics'])} m√©triques\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pr√©paration des Donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation du pr√©processeur\n",
    "print(\"üîÑ Initialisation du pr√©processeur...\")\n",
    "preprocessor = MovieLensPreprocessor(config)\n",
    "\n",
    "# Chargement et pr√©paration des donn√©es\n",
    "print(\"üìä Chargement des donn√©es...\")\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # Chargement\n",
    "    preprocessor.load_data()\n",
    "    print(f\"‚úÖ Donn√©es charg√©es: {len(preprocessor.ratings):,} ratings\")\n",
    "    \n",
    "    # Nettoyage\n",
    "    preprocessor.clean_data()\n",
    "    print(f\"‚úÖ Donn√©es nettoy√©es: {len(preprocessor.ratings):,} ratings\")\n",
    "    \n",
    "    # Traitement des films\n",
    "    preprocessor.process_movies()\n",
    "    print(f\"‚úÖ Films trait√©s: {len(preprocessor.movies):,} films\")\n",
    "    \n",
    "    # Cr√©ation de la matrice utilisateur-film\n",
    "    preprocessor.create_user_movie_matrix()\n",
    "    print(f\"‚úÖ Matrice cr√©√©e: {preprocessor.user_movie_matrix.shape}\")\n",
    "    \n",
    "    # Division des donn√©es\n",
    "    preprocessor.split_data()\n",
    "    print(f\"‚úÖ Donn√©es divis√©es:\")\n",
    "    print(f\"   - Train: {len(preprocessor.train_data):,} ratings\")\n",
    "    print(f\"   - Validation: {len(preprocessor.val_data):,} ratings\")\n",
    "    print(f\"   - Test: {len(preprocessor.test_data):,} ratings\")\n",
    "    \n",
    "    # Sauvegarde\n",
    "    preprocessor.save_processed_data()\n",
    "    print(\"‚úÖ Donn√©es sauvegard√©es\")\n",
    "    \n",
    "    processing_time = time.time() - start_time\n",
    "    print(f\"‚è±Ô∏è Temps de traitement: {processing_time:.2f} secondes\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur lors du pr√©processing: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Mod√®les de Filtrage Collaboratif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation du gestionnaire de filtrage collaboratif\n",
    "print(\"ü§ù === FILTRAGE COLLABORATIF ===")\n",
    "\n",
    "cf_manager = CollaborativeFilteringManager(config)\n",
    "\n",
    "# Chargement des donn√©es pr√©process√©es\n",
    "cf_manager.load_data(\n",
    "    train_data=preprocessor.train_data,\n",
    "    val_data=preprocessor.val_data,\n",
    "    test_data=preprocessor.test_data\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Gestionnaire de filtrage collaboratif initialis√©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entra√Ænement des mod√®les collaboratifs\n",
    "collaborative_results = {}\n",
    "\n",
    "models_to_train = ['svd', 'nmf', 'knn']\n",
    "\n",
    "for model_name in models_to_train:\n",
    "    print(f\"\\nüîÑ Entra√Ænement du mod√®le {model_name.upper()}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Entra√Ænement\n",
    "        cf_manager.train_model(model_name)\n",
    "        \n",
    "        # √âvaluation\n",
    "        metrics = cf_manager.evaluate_model(model_name)\n",
    "        \n",
    "        # Sauvegarde\n",
    "        cf_manager.save_model(model_name)\n",
    "        \n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        collaborative_results[model_name] = {\n",
    "            'metrics': metrics,\n",
    "            'training_time': training_time\n",
    "        }\n",
    "        \n",
    "        print(f\"‚úÖ {model_name.upper()} entra√Æn√© en {training_time:.2f}s\")\n",
    "        print(f\"   RMSE: {metrics.get('rmse', 'N/A'):.4f}\")\n",
    "        print(f\"   MAE: {metrics.get('mae', 'N/A'):.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur avec {model_name}: {e}\")\n",
    "        collaborative_results[model_name] = {'error': str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de recommandations collaboratives\n",
    "print(\"\\nüéØ Test de recommandations collaboratives...\")\n",
    "\n",
    "# S√©lectionner un utilisateur de test\n",
    "test_user_id = preprocessor.test_data['userId'].iloc[0]\n",
    "print(f\"Utilisateur de test: {test_user_id}\")\n",
    "\n",
    "for model_name in models_to_train:\n",
    "    if model_name in collaborative_results and 'error' not in collaborative_results[model_name]:\n",
    "        try:\n",
    "            recommendations = cf_manager.get_recommendations(\n",
    "                model_name=model_name,\n",
    "                user_id=test_user_id,\n",
    "                n_recommendations=5\n",
    "            )\n",
    "            \n",
    "            print(f\"\\n{model_name.upper()} - Top 5 recommandations:\")\n",
    "            for i, (movie_id, score) in enumerate(recommendations, 1):\n",
    "                movie_title = preprocessor.movies[preprocessor.movies['movieId'] == movie_id]['title'].iloc[0]\n",
    "                print(f\"  {i}. {movie_title} (Score: {score:.3f})\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erreur recommandations {model_name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Mod√®les de Filtrage par Contenu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation du gestionnaire de filtrage par contenu\n",
    "print(\"üìù === FILTRAGE PAR CONTENU ===")\n",
    "\n",
    "content_manager = ContentBasedManager(config)\n",
    "\n",
    "# Chargement des donn√©es\n",
    "content_manager.load_data(\n",
    "    movies=preprocessor.movies,\n",
    "    ratings=preprocessor.ratings\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Gestionnaire de filtrage par contenu initialis√©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entra√Ænement des mod√®les de contenu\n",
    "content_results = {}\n",
    "\n",
    "content_models = ['tfidf', 'genre_based']\n",
    "\n",
    "for model_name in content_models:\n",
    "    print(f\"\\nüîÑ Entra√Ænement du mod√®le {model_name.upper()}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Entra√Ænement\n",
    "        content_manager.train_model(model_name)\n",
    "        \n",
    "        # Sauvegarde\n",
    "        content_manager.save_model(model_name)\n",
    "        \n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        content_results[model_name] = {\n",
    "            'training_time': training_time\n",
    "        }\n",
    "        \n",
    "        print(f\"‚úÖ {model_name.upper()} entra√Æn√© en {training_time:.2f}s\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur avec {model_name}: {e}\")\n",
    "        content_results[model_name] = {'error': str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de recommandations par contenu\n",
    "print(\"\\nüéØ Test de recommandations par contenu...\")\n",
    "\n",
    "# S√©lectionner un film de r√©f√©rence\n",
    "reference_movie_id = preprocessor.movies['movieId'].iloc[0]\n",
    "reference_movie_title = preprocessor.movies['title'].iloc[0]\n",
    "print(f\"Film de r√©f√©rence: {reference_movie_title}\")\n",
    "\n",
    "for model_name in content_models:\n",
    "    if model_name in content_results and 'error' not in content_results[model_name]:\n",
    "        try:\n",
    "            recommendations = content_manager.get_recommendations(\n",
    "                model_name=model_name,\n",
    "                movie_id=reference_movie_id,\n",
    "                n_recommendations=5\n",
    "            )\n",
    "            \n",
    "            print(f\"\\n{model_name.upper()} - Films similaires:\")\n",
    "            for i, (movie_id, score) in enumerate(recommendations, 1):\n",
    "                movie_title = preprocessor.movies[preprocessor.movies['movieId'] == movie_id]['title'].iloc[0]\n",
    "                print(f\"  {i}. {movie_title} (Similarit√©: {score:.3f})\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erreur recommandations {model_name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Syst√®mes Hybrides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation du gestionnaire hybride\n",
    "print(\"üîÄ === SYST√àMES HYBRIDES ===")\n",
    "\n",
    "hybrid_manager = HybridSystemManager(config)\n",
    "\n",
    "# Chargement des mod√®les pr√©-entra√Æn√©s\n",
    "hybrid_manager.load_models(\n",
    "    collaborative_manager=cf_manager,\n",
    "    content_manager=content_manager\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Gestionnaire hybride initialis√©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entra√Ænement des mod√®les hybrides\n",
    "hybrid_results = {}\n",
    "\n",
    "hybrid_models = ['weighted', 'switching']\n",
    "\n",
    "for model_name in hybrid_models:\n",
    "    print(f\"\\nüîÑ Entra√Ænement du mod√®le hybride {model_name.upper()}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Entra√Ænement\n",
    "        hybrid_manager.train_model(\n",
    "            model_name=model_name,\n",
    "            train_data=preprocessor.train_data,\n",
    "            val_data=preprocessor.val_data\n",
    "        )\n",
    "        \n",
    "        # Sauvegarde\n",
    "        hybrid_manager.save_model(model_name)\n",
    "        \n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        hybrid_results[model_name] = {\n",
    "            'training_time': training_time\n",
    "        }\n",
    "        \n",
    "        print(f\"‚úÖ {model_name.upper()} entra√Æn√© en {training_time:.2f}s\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur avec {model_name}: {e}\")\n",
    "        hybrid_results[model_name] = {'error': str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de recommandations hybrides\n",
    "print(\"\\nüéØ Test de recommandations hybrides...\")\n",
    "\n",
    "for model_name in hybrid_models:\n",
    "    if model_name in hybrid_results and 'error' not in hybrid_results[model_name]:\n",
    "        try:\n",
    "            recommendations = hybrid_manager.get_recommendations(\n",
    "                model_name=model_name,\n",
    "                user_id=test_user_id,\n",
    "                n_recommendations=5\n",
    "            )\n",
    "            \n",
    "            print(f\"\\n{model_name.upper()} - Top 5 recommandations hybrides:\")\n",
    "            for i, (movie_id, score) in enumerate(recommendations, 1):\n",
    "                movie_title = preprocessor.movies[preprocessor.movies['movieId'] == movie_id]['title'].iloc[0]\n",
    "                print(f\"  {i}. {movie_title} (Score: {score:.3f})\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erreur recommandations {model_name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. √âvaluation Comparative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation de l'√©valuateur\n",
    "print(\"üìä === √âVALUATION COMPARATIVE ===")\n",
    "\n",
    "evaluator = ModelEvaluator(config)\n",
    "\n",
    "# Compilation des r√©sultats\n",
    "all_results = {}\n",
    "\n",
    "# Ajout des r√©sultats collaboratifs\n",
    "for model_name, results in collaborative_results.items():\n",
    "    if 'metrics' in results:\n",
    "        all_results[f'collaborative_{model_name}'] = results['metrics']\n",
    "\n",
    "# √âvaluation des mod√®les de contenu sur les donn√©es de test\n",
    "for model_name in content_models:\n",
    "    if model_name in content_results and 'error' not in content_results[model_name]:\n",
    "        try:\n",
    "            # √âvaluation simplifi√©e pour les mod√®les de contenu\n",
    "            content_metrics = evaluator.evaluate_content_model(\n",
    "                content_manager, model_name, preprocessor.test_data\n",
    "            )\n",
    "            all_results[f'content_{model_name}'] = content_metrics\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Impossible d'√©valuer {model_name}: {e}\")\n",
    "\n",
    "print(f\"‚úÖ {len(all_results)} mod√®les √©valu√©s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage des r√©sultats comparatifs\n",
    "if all_results:\n",
    "    print(\"\\nüìà R√âSULTATS COMPARATIFS:\")\n",
    "    print(\"=" * 60)\n",
    "    \n",
    "    # Cr√©ation d'un DataFrame pour la comparaison\n",
    "    results_df = pd.DataFrame(all_results).T\n",
    "    \n",
    "    # Affichage des m√©triques principales\n",
    "    if 'rmse' in results_df.columns:\n",
    "        print(\"\\nüéØ RMSE (plus bas = meilleur):\")\n",
    "        rmse_sorted = results_df['rmse'].dropna().sort_values()\n",
    "        for model, rmse in rmse_sorted.items():\n",
    "            print(f\"  {model:20s}: {rmse:.4f}\")\n",
    "    \n",
    "    if 'mae' in results_df.columns:\n",
    "        print(\"\\nüéØ MAE (plus bas = meilleur):\")\n",
    "        mae_sorted = results_df['mae'].dropna().sort_values()\n",
    "        for model, mae in mae_sorted.items():\n",
    "            print(f\"  {model:20s}: {mae:.4f}\")\n",
    "    \n",
    "    # Affichage du tableau complet\n",
    "    print(\"\\nüìä TABLEAU COMPLET DES R√âSULTATS:\")\n",
    "    display(results_df.round(4))\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Aucun r√©sultat disponible pour la comparaison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des r√©sultats\n",
    "if all_results and len(all_results) > 1:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Graphique RMSE\n",
    "    if 'rmse' in results_df.columns:\n",
    "        rmse_data = results_df['rmse'].dropna()\n",
    "        if len(rmse_data) > 0:\n",
    "            rmse_data.plot(kind='bar', ax=axes[0], color='skyblue', edgecolor='black')\n",
    "            axes[0].set_title('Comparaison RMSE par Mod√®le')\n",
    "            axes[0].set_ylabel('RMSE')\n",
    "            axes[0].tick_params(axis='x', rotation=45)\n",
    "            axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Graphique MAE\n",
    "    if 'mae' in results_df.columns:\n",
    "        mae_data = results_df['mae'].dropna()\n",
    "        if len(mae_data) > 0:\n",
    "            mae_data.plot(kind='bar', ax=axes[1], color='lightcoral', edgecolor='black')\n",
    "            axes[1].set_title('Comparaison MAE par Mod√®le')\n",
    "            axes[1].set_ylabel('MAE')\n",
    "            axes[1].tick_params(axis='x', rotation=45)\n",
    "            axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Graphique radar pour comparaison multi-m√©triques\n",
    "    if len(results_df.columns) >= 3:\n",
    "        try:\n",
    "            # Normalisation des m√©triques pour le graphique radar\n",
    "            normalized_df = results_df.copy()\n",
    "            for col in normalized_df.columns:\n",
    "                if col in ['rmse', 'mae']:  # M√©triques √† minimiser\n",
    "                    normalized_df[col] = 1 - (normalized_df[col] / normalized_df[col].max())\n",
    "                else:  # M√©triques √† maximiser\n",
    "                    normalized_df[col] = normalized_df[col] / normalized_df[col].max()\n",
    "            \n",
    "            # Cr√©ation du graphique radar avec plotly\n",
    "            fig_radar = go.Figure()\n",
    "            \n",
    "            for model in normalized_df.index:\n",
    "                fig_radar.add_trace(go.Scatterpolar(\n",
    "                    r=normalized_df.loc[model].values,\n",
    "                    theta=normalized_df.columns,\n",
    "                    fill='toself',\n",
    "                    name=model\n",
    "                ))\n",
    "            \n",
    "            fig_radar.update_layout(\n",
    "                polar=dict(\n",
    "                    radialaxis=dict(\n",
    "                        visible=True,\n",
    "                        range=[0, 1]\n",
    "                    )),\n",
    "                showlegend=True,\n",
    "                title=\"Comparaison Multi-M√©triques des Mod√®les\"\n",
    "            )\n",
    "            \n",
    "            fig_radar.show()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Impossible de cr√©er le graphique radar: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analyse des Temps d'Ex√©cution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilation des temps d'entra√Ænement\n",
    "training_times = {}\n",
    "\n",
    "# Temps collaboratifs\n",
    "for model_name, results in collaborative_results.items():\n",
    "    if 'training_time' in results:\n",
    "        training_times[f'collaborative_{model_name}'] = results['training_time']\n",
    "\n",
    "# Temps de contenu\n",
    "for model_name, results in content_results.items():\n",
    "    if 'training_time' in results:\n",
    "        training_times[f'content_{model_name}'] = results['training_time']\n",
    "\n",
    "# Temps hybrides\n",
    "for model_name, results in hybrid_results.items():\n",
    "    if 'training_time' in results:\n",
    "        training_times[f'hybrid_{model_name}'] = results['training_time']\n",
    "\n",
    "if training_times:\n",
    "    print(\"‚è±Ô∏è TEMPS D'ENTRA√éNEMENT:\")\n",
    "    print(\"=" * 40)\n",
    "    \n",
    "    # Tri par temps\n",
    "    sorted_times = sorted(training_times.items(), key=lambda x: x[1])\n",
    "    \n",
    "    for model, time_sec in sorted_times:\n",
    "        print(f\"  {model:25s}: {time_sec:6.2f}s\")\n",
    "    \n",
    "    # Visualisation\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    models = [item[0] for item in sorted_times]\n",
    "    times = [item[1] for item in sorted_times]\n",
    "    \n",
    "    bars = plt.bar(models, times, color='lightgreen', edgecolor='black')\n",
    "    plt.title('Temps d\\'Entra√Ænement par Mod√®le')\n",
    "    plt.ylabel('Temps (secondes)')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Ajout des valeurs sur les barres\n",
    "    for bar, time_val in zip(bars, times):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
    "                f'{time_val:.1f}s', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Recommandations et Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse des r√©sultats et recommandations\n",
    "print(\"üéØ === ANALYSE ET RECOMMANDATIONS ===")\n",
    "print()\n",
    "\n",
    "# Identification du meilleur mod√®le\n",
    "if all_results:\n",
    "    if 'rmse' in results_df.columns:\n",
    "        best_rmse_model = results_df['rmse'].dropna().idxmin()\n",
    "        best_rmse_value = results_df.loc[best_rmse_model, 'rmse']\n",
    "        print(f\"üèÜ MEILLEUR MOD√àLE (RMSE): {best_rmse_model}\")\n",
    "        print(f\"   RMSE: {best_rmse_value:.4f}\")\n",
    "    \n",
    "    if 'mae' in results_df.columns:\n",
    "        best_mae_model = results_df['mae'].dropna().idxmin()\n",
    "        best_mae_value = results_df.loc[best_mae_model, 'mae']\n",
    "        print(f\"üèÜ MEILLEUR MOD√àLE (MAE): {best_mae_model}\")\n",
    "        print(f\"   MAE: {best_mae_value:.4f}\")\n",
    "\n",
    "print(\"\\nüìã RECOMMANDATIONS POUR LA PRODUCTION:\")\n",
    "print(\"\\n1. üöÄ D√âPLOIEMENT:\")\n",
    "print(\"   ‚Ä¢ Utiliser le mod√®le avec le meilleur RMSE pour la pr√©diction de ratings\")\n",
    "print(\"   ‚Ä¢ Impl√©menter un syst√®me hybride pour combiner les approches\")\n",
    "print(\"   ‚Ä¢ Mettre en place un cache pour les recommandations fr√©quentes\")\n",
    "\n",
    "print(\"\\n2. üîÑ AM√âLIORATION CONTINUE:\")\n",
    "print(\"   ‚Ä¢ R√©entra√Æner les mod√®les p√©riodiquement avec de nouvelles donn√©es\")\n",
    "print(\"   ‚Ä¢ Monitorer les performances en temps r√©el\")\n",
    "print(\"   ‚Ä¢ Collecter les feedbacks utilisateurs pour l'am√©lioration\")\n",
    "\n",
    "print(\"\\n3. üìä M√âTRIQUES DE SUIVI:\")\n",
    "print(\"   ‚Ä¢ RMSE/MAE pour la pr√©cision des pr√©dictions\")\n",
    "print(\"   ‚Ä¢ Taux de clic sur les recommandations\")\n",
    "print(\"   ‚Ä¢ Diversit√© et nouveaut√© des recommandations\")\n",
    "print(\"   ‚Ä¢ Temps de r√©ponse de l'API\")\n",
    "\n",
    "print(\"\\n4. üõ°Ô∏è GESTION DES PROBL√àMES:\")\n",
    "print(\"   ‚Ä¢ Cold start: Recommandations bas√©es sur la popularit√©\")\n",
    "print(\"   ‚Ä¢ Sparsit√©: Techniques de r√©gularisation\")\n",
    "print(\"   ‚Ä¢ Scalabilit√©: Optimisation des algorithmes et infrastructure\")\n",
    "\n",
    "print(\"\\n5. üé® EXP√âRIENCE UTILISATEUR:\")\n",
    "print(\"   ‚Ä¢ Interface intuitive avec explications des recommandations\")\n",
    "print(\"   ‚Ä¢ Personnalisation bas√©e sur l'historique\")\n",
    "print(\"   ‚Ä¢ Options de filtrage par genre, ann√©e, etc.\")\n",
    "print(\"   ‚Ä¢ Syst√®me de feedback pour am√©liorer les recommandations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Sauvegarde des R√©sultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde compl√®te des r√©sultats\n",
    "modeling_results = {\n",
    "    'experiment_info': {\n",
    "        'date': str(datetime.now()),\n",
    "        'dataset_size': len(preprocessor.ratings) if hasattr(preprocessor, 'ratings') else 0,\n",
    "        'train_size': len(preprocessor.train_data) if hasattr(preprocessor, 'train_data') else 0,\n",
    "        'test_size': len(preprocessor.test_data) if hasattr(preprocessor, 'test_data') else 0\n",
    "    },\n",
    "    'collaborative_results': collaborative_results,\n",
    "    'content_results': content_results,\n",
    "    'hybrid_results': hybrid_results,\n",
    "    'training_times': training_times,\n",
    "    'evaluation_metrics': all_results,\n",
    "    'best_models': {}\n",
    "}\n",
    "\n",
    "# Identification des meilleurs mod√®les\n",
    "if all_results and len(all_results) > 0:\n",
    "    if 'rmse' in results_df.columns and not results_df['rmse'].dropna().empty:\n",
    "        modeling_results['best_models']['rmse'] = {\n",
    "            'model': results_df['rmse'].dropna().idxmin(),\n",
    "            'value': float(results_df['rmse'].dropna().min())\n",
    "        }\n",
    "    \n",
    "    if 'mae' in results_df.columns and not results_df['mae'].dropna().empty:\n",
    "        modeling_results['best_models']['mae'] = {\n",
    "            'model': results_df['mae'].dropna().idxmin(),\n",
    "            'value': float(results_df['mae'].dropna().min())\n",
    "        }\n",
    "\n",
    "# Sauvegarde\n",
    "results_path = Path('../data/processed/modeling_results.json')\n",
    "results_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(results_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(modeling_results, f, indent=2, ensure_ascii=False, default=str)\n",
    "\n",
    "print(\"‚úÖ R√©sultats sauvegard√©s dans data/processed/modeling_results.json\")\n",
    "\n",
    "# R√©sum√© final\n",
    "print(\"\\nüéâ === R√âSUM√â DE LA MOD√âLISATION ===")\n",
    "print(f\"üìä Mod√®les entra√Æn√©s: {len(collaborative_results) + len(content_results) + len(hybrid_results)}\")\n",
    "print(f\"‚è±Ô∏è Temps total: {sum(training_times.values()):.2f} secondes\")\n",
    "print(f\"üìà M√©triques calcul√©es: {len(all_results)} mod√®les √©valu√©s\")\n",
    "print(\"üöÄ Pr√™t pour le d√©ploiement!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}