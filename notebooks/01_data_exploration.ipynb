{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration des Donn√©es - MovieLens 20M\n",
    "\n",
    "**Auteur:** Dady Akrou Cyrille  \n",
    "**Email:** cyrilledady0501@gmail.com  \n",
    "**Date:** D√©cembre 2024\n",
    "\n",
    "Ce notebook explore le dataset MovieLens 20M pour comprendre la structure des donn√©es et identifier les patterns pour notre syst√®me de recommandation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports n√©cessaires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Configuration des graphiques\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement de la configuration\n",
    "config_path = Path('../config/config.yaml')\n",
    "\n",
    "with open(config_path, 'r', encoding='utf-8') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Chemins des donn√©es\n",
    "data_path = Path(config['data']['base_path'])\n",
    "dataset_files = config['data']['dataset_files']\n",
    "\n",
    "print(\"Configuration charg√©e avec succ√®s!\")\n",
    "print(f\"Chemin des donn√©es: {data_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement des Donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour charger les donn√©es\n",
    "def load_data():\n",
    "    \"\"\"Charge tous les fichiers du dataset MovieLens\"\"\"\n",
    "    data = {}\n",
    "    \n",
    "    try:\n",
    "        # Chargement des ratings\n",
    "        print(\"Chargement des ratings...\")\n",
    "        data['ratings'] = pd.read_csv(data_path / dataset_files['ratings'])\n",
    "        print(f\"‚úì Ratings: {data['ratings'].shape}\")\n",
    "        \n",
    "        # Chargement des films\n",
    "        print(\"Chargement des films...\")\n",
    "        data['movies'] = pd.read_csv(data_path / dataset_files['movies'])\n",
    "        print(f\"‚úì Films: {data['movies'].shape}\")\n",
    "        \n",
    "        # Chargement des tags\n",
    "        print(\"Chargement des tags...\")\n",
    "        data['tags'] = pd.read_csv(data_path / dataset_files['tags'])\n",
    "        print(f\"‚úì Tags: {data['tags'].shape}\")\n",
    "        \n",
    "        # Chargement des liens\n",
    "        print(\"Chargement des liens...\")\n",
    "        data['links'] = pd.read_csv(data_path / dataset_files['links'])\n",
    "        print(f\"‚úì Liens: {data['links'].shape}\")\n",
    "        \n",
    "        # Chargement des genome scores (optionnel)\n",
    "        try:\n",
    "            print(\"Chargement des genome scores...\")\n",
    "            data['genome_scores'] = pd.read_csv(data_path / dataset_files['genome_scores'])\n",
    "            print(f\"‚úì Genome Scores: {data['genome_scores'].shape}\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"‚ö†Ô∏è Genome scores non trouv√©\")\n",
    "        \n",
    "        # Chargement des genome tags (optionnel)\n",
    "        try:\n",
    "            print(\"Chargement des genome tags...\")\n",
    "            data['genome_tags'] = pd.read_csv(data_path / dataset_files['genome_tags'])\n",
    "            print(f\"‚úì Genome Tags: {data['genome_tags'].shape}\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"‚ö†Ô∏è Genome tags non trouv√©\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur lors du chargement: {e}\")\n",
    "        return None\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Chargement des donn√©es\n",
    "data = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploration des Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data and 'ratings' in data:\n",
    "    ratings = data['ratings']\n",
    "    \n",
    "    print(\"=== ANALYSE DES RATINGS ===\")",
    "    print(f\"Nombre total de ratings: {len(ratings):,}\")",
    "    print(f\"Nombre d'utilisateurs uniques: {ratings['userId'].nunique():,}\")",
    "    print(f\"P√©riode: {pd.to_datetime(ratings['timestamp'], unit='s').min()} √† {pd.to_datetime(ratings['timestamp'], unit='s').max()}\")",
    "    \n",
    "    # Statistiques des ratings\n",
    "    print(\"\\n=== STATISTIQUES DES RATINGS ===\")",
    "    print(ratings['rating'].describe())\n",
    "    \n",
    "    # Affichage des premi√®res lignes\n",
    "    print(\"\\n=== APER√áU DES DONN√âES ===\")",
    "display(ratings.head(10))\n",
    "\n",
    "# Informations sur les types de donn√©es\n",
    "print(\"\\n=== INFORMATIONS SUR LES DONN√âES ===\")",
    "print(ratings.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution des ratings\n",
    "if data and 'ratings' in data:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Distribution des ratings\n",
    "    ratings['rating'].hist(bins=10, ax=axes[0,0], edgecolor='black')\n",
    "    axes[0,0].set_title('Distribution des Ratings')\n",
    "    axes[0,0].set_xlabel('Rating')\n",
    "    axes[0,0].set_ylabel('Fr√©quence')\n",
    "    \n",
    "    # Nombre de ratings par utilisateur\n",
    "    user_counts = ratings['userId'].value_counts()\n",
    "    user_counts.hist(bins=50, ax=axes[0,1], edgecolor='black')\n",
    "    axes[0,1].set_title('Distribution du Nombre de Ratings par Utilisateur')\n",
    "    axes[0,1].set_xlabel('Nombre de Ratings')\n",
    "    axes[0,1].set_ylabel('Nombre d\\'Utilisateurs')\n",
    "    axes[0,1].set_xscale('log')\n",
    "    axes[0,1].set_yscale('log')\n",
    "    \n",
    "    # Nombre de ratings par film\n",
    "    movie_counts = ratings['movieId'].value_counts()\n",
    "    movie_counts.hist(bins=50, ax=axes[1,0], edgecolor='black')\n",
    "    axes[1,0].set_title('Distribution du Nombre de Ratings par Film')\n",
    "    axes[1,0].set_xlabel('Nombre de Ratings')\n",
    "    axes[1,0].set_ylabel('Nombre de Films')\n",
    "    axes[1,0].set_xscale('log')\n",
    "    axes[1,0].set_yscale('log')\n",
    "    \n",
    "    # √âvolution temporelle des ratings\n",
    "    ratings['date'] = pd.to_datetime(ratings['timestamp'], unit='s')\n",
    "    ratings['year'] = ratings['date'].dt.year\n",
    "    yearly_counts = ratings['year'].value_counts().sort_index()\n",
    "    yearly_counts.plot(ax=axes[1,1])\n",
    "    axes[1,1].set_title('√âvolution du Nombre de Ratings par Ann√©e')\n",
    "    axes[1,1].set_xlabel('Ann√©e')\n",
    "    axes[1,1].set_ylabel('Nombre de Ratings')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploration des Films"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data and 'movies' in data:\n",
    "    movies = data['movies']\n",
    "    \n",
    "    print(\"=== ANALYSE DES FILMS ===)\n",
    "    print(f\"Nombre total de films: {len(movies):,}\")\n",
    "    \n",
    "    # Extraction de l'ann√©e depuis le titre\n",
    "    movies['year'] = movies['title'].str.extract(r'\\((\\d{4})\\)$')[0]\n",
    "    movies['year'] = pd.to_numeric(movies['year'], errors='coerce')\n",
    "    \n",
    "    # Nettoyage du titre\n",
    "    movies['clean_title'] = movies['title'].str.replace(r'\\s*\\(\\d{4}\\)$', '', regex=True)\n",
    "    \n",
    "    print(f\"P√©riode des films: {movies['year'].min():.0f} √† {movies['year'].max():.0f}\")\n",
    "    \n",
    "    # Affichage des premi√®res lignes\n",
    "    print(\"\\n=== APER√áU DES FILMS ===)\n",
    "    display(movies.head(10))\n",
    "    \n",
    "    # Analyse des genres\n",
    "    print(\"\\n=== ANALYSE DES GENRES ===)\n",
    "    # S√©paration des genres\n",
    "    all_genres = []\n",
    "    for genres in movies['genres'].dropna():\n",
    "        all_genres.extend(genres.split('|'))\n",
    "    \n",
    "    genre_counts = pd.Series(all_genres).value_counts()\n",
    "    print(f\"Nombre de genres uniques: {len(genre_counts)}\")\n",
    "    print(\"\\nTop 10 des genres:\")\n",
    "    print(genre_counts.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisations des films\n",
    "if data and 'movies' in data:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Distribution des ann√©es\n",
    "    movies['year'].hist(bins=30, ax=axes[0,0], edgecolor='black')\n",
    "    axes[0,0].set_title('Distribution des Films par Ann√©e')\n",
    "    axes[0,0].set_xlabel('Ann√©e')\n",
    "    axes[0,0].set_ylabel('Nombre de Films')\n",
    "    \n",
    "    # Top genres\n",
    "    genre_counts.head(15).plot(kind='barh', ax=axes[0,1])\n",
    "    axes[0,1].set_title('Top 15 des Genres')\n",
    "    axes[0,1].set_xlabel('Nombre de Films')\n",
    "    \n",
    "    # √âvolution des genres dans le temps\n",
    "    top_genres = genre_counts.head(5).index\n",
    "    for genre in top_genres:\n",
    "        genre_by_year = []\n",
    "        years = sorted(movies['year'].dropna().unique())\n",
    "        for year in years:\n",
    "            year_movies = movies[movies['year'] == year]\n",
    "            genre_count = year_movies['genres'].str.contains(genre, na=False).sum()\n",
    "            genre_by_year.append(genre_count)\n",
    "        axes[1,0].plot(years, genre_by_year, label=genre, marker='o', markersize=2)\n",
    "    \n",
    "    axes[1,0].set_title('√âvolution des Top 5 Genres dans le Temps')\n",
    "    axes[1,0].set_xlabel('Ann√©e')\n",
    "    axes[1,0].set_ylabel('Nombre de Films')\n",
    "    axes[1,0].legend()\n",
    "    \n",
    "    # Nombre de genres par film\n",
    "    movies['genre_count'] = movies['genres'].str.count('\\|') + 1\n",
    "    movies['genre_count'].hist(bins=10, ax=axes[1,1], edgecolor='black')\n",
    "    axes[1,1].set_title('Distribution du Nombre de Genres par Film')\n",
    "    axes[1,1].set_xlabel('Nombre de Genres')\n",
    "    axes[1,1].set_ylabel('Nombre de Films')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyse Crois√©e Ratings-Films"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fusion des donn√©es\n",
    "if data and 'ratings' in data and 'movies' in data:\n",
    "    # Fusion ratings et movies\n",
    "    ratings_movies = ratings.merge(movies, on='movieId', how='left')\n",
    "    \n",
    "    print(\"=== ANALYSE CROIS√âE ===)\n",
    "    print(f\"Donn√©es fusionn√©es: {len(ratings_movies):,} ratings\")\n",
    "    \n",
    "    # Films les plus populaires\n",
    "    popular_movies = ratings_movies.groupby(['movieId', 'title']).agg({\n",
    "        'rating': ['count', 'mean']\n",
    "    }).round(2)\n",
    "    \n",
    "    popular_movies.columns = ['num_ratings', 'avg_rating']\n",
    "    popular_movies = popular_movies.reset_index()\n",
    "    \n",
    "    # Filtrer les films avec au moins 100 ratings\n",
    "    popular_movies_filtered = popular_movies[popular_movies['num_ratings'] >= 100]\n",
    "    \n",
    "    print(\"\\n=== TOP 10 FILMS LES PLUS POPULAIRES (>100 ratings) ===)\n",
    "    top_popular = popular_movies_filtered.nlargest(10, 'num_ratings')\n",
    "    display(top_popular)\n",
    "    \n",
    "    print(\"\\n=== TOP 10 FILMS LES MIEUX NOT√âS (>100 ratings) ===)\n",
    "    top_rated = popular_movies_filtered.nlargest(10, 'avg_rating')\n",
    "    display(top_rated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse par genre\n",
    "if data and 'ratings' in data and 'movies' in data:\n",
    "    # Analyse des ratings par genre\n",
    "    genre_ratings = []\n",
    "    \n",
    "    for idx, row in movies.iterrows():\n",
    "        if pd.notna(row['genres']):\n",
    "            genres = row['genres'].split('|')\n",
    "            movie_ratings = ratings[ratings['movieId'] == row['movieId']]['rating']\n",
    "            \n",
    "            for genre in genres:\n",
    "                for rating in movie_ratings:\n",
    "                    genre_ratings.append({'genre': genre, 'rating': rating})\n",
    "    \n",
    "    genre_ratings_df = pd.DataFrame(genre_ratings)\n",
    "    \n",
    "    # Statistiques par genre\n",
    "    genre_stats = genre_ratings_df.groupby('genre')['rating'].agg(['count', 'mean', 'std']).round(2)\n",
    "    genre_stats = genre_stats.sort_values('mean', ascending=False)\n",
    "    \n",
    "    print(\"=== STATISTIQUES PAR GENRE ===)\n",
    "    display(genre_stats.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisations avanc√©es\n",
    "if data and 'ratings' in data and 'movies' in data:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Relation entre popularit√© et note moyenne\n",
    "    axes[0,0].scatter(popular_movies['num_ratings'], popular_movies['avg_rating'], alpha=0.6)\n",
    "    axes[0,0].set_xlabel('Nombre de Ratings')\n",
    "    axes[0,0].set_ylabel('Note Moyenne')\n",
    "    axes[0,0].set_title('Relation Popularit√© vs Note Moyenne')\n",
    "    axes[0,0].set_xscale('log')\n",
    "    \n",
    "    # Distribution des notes moyennes par genre (top 10)\n",
    "    top_genres_stats = genre_stats.head(10)\n",
    "    top_genres_stats['mean'].plot(kind='barh', ax=axes[0,1])\n",
    "    axes[0,1].set_title('Note Moyenne par Genre (Top 10)')\n",
    "    axes[0,1].set_xlabel('Note Moyenne')\n",
    "    \n",
    "    # √âvolution des ratings dans le temps\n",
    "    monthly_ratings = ratings_movies.groupby(ratings_movies['date'].dt.to_period('M'))['rating'].mean()\n",
    "    monthly_ratings.plot(ax=axes[1,0])\n",
    "    axes[1,0].set_title('√âvolution de la Note Moyenne dans le Temps')\n",
    "    axes[1,0].set_xlabel('Date')\n",
    "    axes[1,0].set_ylabel('Note Moyenne')\n",
    "    axes[1,0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Heatmap des ratings par heure et jour de la semaine\n",
    "    ratings_movies['hour'] = ratings_movies['date'].dt.hour\n",
    "    ratings_movies['day_of_week'] = ratings_movies['date'].dt.day_name()\n",
    "    \n",
    "    # Cr√©er une heatmap simplifi√©e\n",
    "    hour_day_counts = ratings_movies.groupby(['day_of_week', 'hour']).size().unstack(fill_value=0)\n",
    "    \n",
    "    # R√©organiser les jours de la semaine\n",
    "    day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    hour_day_counts = hour_day_counts.reindex(day_order)\n",
    "    \n",
    "    im = axes[1,1].imshow(hour_day_counts.values, cmap='YlOrRd', aspect='auto')\n",
    "    axes[1,1].set_xticks(range(0, 24, 4))\n",
    "    axes[1,1].set_xticklabels(range(0, 24, 4))\n",
    "    axes[1,1].set_yticks(range(len(day_order)))\n",
    "    axes[1,1].set_yticklabels(day_order)\n",
    "    axes[1,1].set_title('Activit√© des Ratings par Heure et Jour')\n",
    "    axes[1,1].set_xlabel('Heure')\n",
    "    axes[1,1].set_ylabel('Jour de la Semaine')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyse de la Sparsit√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse de la sparsit√© de la matrice utilisateur-film\n",
    "if data and 'ratings' in data:\n",
    "    n_users = ratings['userId'].nunique()\n",
    "    n_movies = ratings['movieId'].nunique()\n",
    "    n_ratings = len(ratings)\n",
    "    \n",
    "    # Calcul de la sparsit√©\n",
    "    total_possible_ratings = n_users * n_movies\n",
    "    sparsity = (1 - (n_ratings / total_possible_ratings)) * 100\n",
    "    \n",
    "    print(\"=== ANALYSE DE LA SPARSIT√â ===)\n",
    "    print(f\"Nombre d'utilisateurs: {n_users:,}\")\n",
    "    print(f\"Nombre de films: {n_movies:,}\")\n",
    "    print(f\"Nombre de ratings: {n_ratings:,}\")\n",
    "    print(f\"Ratings possibles: {total_possible_ratings:,}\")\n",
    "    print(f\"Sparsit√©: {sparsity:.2f}%\")\n",
    "    print(f\"Densit√©: {100-sparsity:.2f}%\")\n",
    "    \n",
    "    # Distribution des utilisateurs actifs\n",
    "    user_activity = ratings['userId'].value_counts()\n",
    "    \n",
    "    print(\"\\n=== ACTIVIT√â DES UTILISATEURS ===\"),\n",
    "    print(f\"Utilisateur le plus actif: {user_activity.max()} ratings\")\n",
    "    print(f\"Utilisateur le moins actif: {user_activity.min()} ratings\")\n",
    "    print(f\"Moyenne de ratings par utilisateur: {user_activity.mean():.1f}\")\n",
    "    print(f\"M√©diane de ratings par utilisateur: {user_activity.median():.1f}\")\n",
    "    \n",
    "    # Distribution des films populaires\n",
    "    movie_popularity = ratings['movieId'].value_counts()\n",
    "    \n",
    "    print(\"\\n=== POPULARIT√â DES FILMS ===)\n",
    "    print(f\"Film le plus populaire: {movie_popularity.max()} ratings\")\n",
    "    print(f\"Film le moins populaire: {movie_popularity.min()} ratings\")\n",
    "    print(f\"Moyenne de ratings par film: {movie_popularity.mean():.1f}\")\n",
    "    print(f\"M√©diane de ratings par film: {movie_popularity.median():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Recommandations pour le Syst√®me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommandations bas√©es sur l'analyse\n",
    "print(\"=== RECOMMANDATIONS POUR LE SYST√àME ===)\n",
    "print()\n",
    "\n",
    "print(\"1. üìä DONN√âES:\")\n",
    "if data and 'ratings' in data:\n",
    "    print(f\"   ‚Ä¢ Dataset volumineux: {len(ratings):,} ratings\")\n",
    "    print(f\"   ‚Ä¢ Sparsit√© √©lev√©e: {sparsity:.1f}% - n√©cessite des techniques robustes\")\n",
    "    print(f\"   ‚Ä¢ P√©riode: {ratings_movies['year'].min():.0f}-{ratings_movies['year'].max():.0f} - donn√©es historiques riches\")\n",
    "\n",
    "print(\"\\n2. üéØ APPROCHES RECOMMAND√âES:\")\n",
    "print(\"   ‚Ä¢ Filtrage collaboratif: Exploiter les similarit√©s utilisateur-film\")\n",
    "print(\"   ‚Ä¢ Filtrage par contenu: Utiliser les genres et m√©tadonn√©es\")\n",
    "print(\"   ‚Ä¢ Syst√®me hybride: Combiner les deux approches\")\n",
    "print(\"   ‚Ä¢ Factorisation matricielle: SVD, NMF pour g√©rer la sparsit√©\")\n",
    "\n",
    "print(\"\\n3. ‚ö†Ô∏è D√âFIS IDENTIFI√âS:\")\n",
    "print(\"   ‚Ä¢ Cold start: Nouveaux utilisateurs/films\")\n",
    "print(\"   ‚Ä¢ Sparsit√©: Peu d'interactions par utilisateur\")\n",
    "print(\"   ‚Ä¢ Scalabilit√©: Volume important de donn√©es\")\n",
    "print(\"   ‚Ä¢ Biais temporel: √âvolution des pr√©f√©rences\")\n",
    "\n",
    "print(\"\\n4. üõ†Ô∏è TECHNIQUES √Ä IMPL√âMENTER:\")\n",
    "print(\"   ‚Ä¢ SVD (Singular Value Decomposition)\")\n",
    "print(\"   ‚Ä¢ NMF (Non-negative Matrix Factorization)\")\n",
    "print(\"   ‚Ä¢ KNN (K-Nearest Neighbors)\")\n",
    "print(\"   ‚Ä¢ TF-IDF pour le contenu textuel\")\n",
    "print(\"   ‚Ä¢ Similarit√© cosinus\")\n",
    "\n",
    "print(\"\\n5. üìà M√âTRIQUES D'√âVALUATION:\")\n",
    "print(\"   ‚Ä¢ RMSE, MAE pour la pr√©cision\")\n",
    "print(\"   ‚Ä¢ Precision@K, Recall@K pour le ranking\")\n",
    "print(\"   ‚Ä¢ NDCG pour la qualit√© du classement\")\n",
    "print(\"   ‚Ä¢ Coverage, Diversity pour la vari√©t√©\")\n",
    "\n",
    "print(\"\\n6. üîß OPTIMISATIONS:\")\n",
    "print(\"   ‚Ä¢ Filtrage des utilisateurs/films peu actifs\")\n",
    "print(\"   ‚Ä¢ Normalisation des ratings\")\n",
    "print(\"   ‚Ä¢ Validation temporelle\")\n",
    "print(\"   ‚Ä¢ Cache pour les recommandations fr√©quentes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Sauvegarde des Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde des statistiques importantes\n",
    "insights = {\n",
    "    'dataset_stats': {\n",
    "        'total_ratings': len(ratings) if data and 'ratings' in data else 0,\n",
    "        'unique_users': ratings['userId'].nunique() if data and 'ratings' in data else 0,\n",
    "        'unique_movies': ratings['movieId'].nunique() if data and 'ratings' in data else 0,\n",
    "        'sparsity_percent': sparsity if data and 'ratings' in data else 0,\n",
    "        'rating_range': [ratings['rating'].min(), ratings['rating'].max()] if data and 'ratings' in data else [0, 0],\n",
    "        'time_range': [str(ratings['date'].min()), str(ratings['date'].max())] if data and 'ratings' in data else ['', '']\n",
    "    },\n",
    "    'recommendations': {\n",
    "        'filtering_thresholds': {\n",
    "            'min_user_ratings': 20,\n",
    "            'min_movie_ratings': 10\n",
    "        },\n",
    "        'models_to_implement': ['SVD', 'NMF', 'KNN', 'Content-based', 'Hybrid'],\n",
    "        'evaluation_metrics': ['RMSE', 'MAE', 'Precision@K', 'Recall@K', 'NDCG@K']\n",
    "    },\n",
    "    'analysis_date': str(datetime.now())\n",
    "}\n",
    "\n",
    "# Sauvegarde\n",
    "import json\n",
    "\n",
    "with open('../data/processed/data_insights.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(insights, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"‚úÖ Insights sauvegard√©s dans data/processed/data_insights.json\")\n",
    "print(\"\\nüìã R√âSUM√â DE L'EXPLORATION:\")\n",
    "print(f\"   ‚Ä¢ {insights['dataset_stats']['total_ratings']:,} ratings analys√©s\")\n",
    "print(f\"   ‚Ä¢ {insights['dataset_stats']['unique_users']:,} utilisateurs uniques\")\n",
    "print(f\"   ‚Ä¢ {insights['dataset_stats']['unique_movies']:,} films uniques\")\n",
    "print(f\"   ‚Ä¢ Sparsit√©: {insights['dataset_stats']['sparsity_percent']:.1f}%\")\n",
    "print(\"   ‚Ä¢ Pr√™t pour la phase de mod√©lisation! üöÄ\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}