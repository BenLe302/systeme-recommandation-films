{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration des Données - MovieLens 20M\n",
    "\n",
    "**Auteur:** Dady Akrou Cyrille  \n",
    "**Email:** cyrilledady0501@gmail.com  \n",
    "**Date:** Décembre 2024\n",
    "\n",
    "Ce notebook explore le dataset MovieLens 20M pour comprendre la structure des données et identifier les patterns pour notre système de recommandation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports nécessaires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Configuration des graphiques\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement de la configuration\n",
    "config_path = Path('../config/config.yaml')\n",
    "\n",
    "with open(config_path, 'r', encoding='utf-8') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Chemins des données\n",
    "data_path = Path(config['data']['base_path'])\n",
    "dataset_files = config['data']['dataset_files']\n",
    "\n",
    "print(\"Configuration chargée avec succès!\")\n",
    "print(f\"Chemin des données: {data_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement des Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour charger les données\n",
    "def load_data():\n",
    "    \"\"\"Charge tous les fichiers du dataset MovieLens\"\"\"\n",
    "    data = {}\n",
    "    \n",
    "    try:\n",
    "        # Chargement des ratings\n",
    "        print(\"Chargement des ratings...\")\n",
    "        data['ratings'] = pd.read_csv(data_path / dataset_files['ratings'])\n",
    "        print(f\"✓ Ratings: {data['ratings'].shape}\")\n",
    "        \n",
    "        # Chargement des films\n",
    "        print(\"Chargement des films...\")\n",
    "        data['movies'] = pd.read_csv(data_path / dataset_files['movies'])\n",
    "        print(f\"✓ Films: {data['movies'].shape}\")\n",
    "        \n",
    "        # Chargement des tags\n",
    "        print(\"Chargement des tags...\")\n",
    "        data['tags'] = pd.read_csv(data_path / dataset_files['tags'])\n",
    "        print(f\"✓ Tags: {data['tags'].shape}\")\n",
    "        \n",
    "        # Chargement des liens\n",
    "        print(\"Chargement des liens...\")\n",
    "        data['links'] = pd.read_csv(data_path / dataset_files['links'])\n",
    "        print(f\"✓ Liens: {data['links'].shape}\")\n",
    "        \n",
    "        # Chargement des genome scores (optionnel)\n",
    "        try:\n",
    "            print(\"Chargement des genome scores...\")\n",
    "            data['genome_scores'] = pd.read_csv(data_path / dataset_files['genome_scores'])\n",
    "            print(f\"✓ Genome Scores: {data['genome_scores'].shape}\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"⚠️ Genome scores non trouvé\")\n",
    "        \n",
    "        # Chargement des genome tags (optionnel)\n",
    "        try:\n",
    "            print(\"Chargement des genome tags...\")\n",
    "            data['genome_tags'] = pd.read_csv(data_path / dataset_files['genome_tags'])\n",
    "            print(f\"✓ Genome Tags: {data['genome_tags'].shape}\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"⚠️ Genome tags non trouvé\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur lors du chargement: {e}\")\n",
    "        return None\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Chargement des données\n",
    "data = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploration des Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data and 'ratings' in data:\n",
    "    ratings = data['ratings']\n",
    "    \n",
    "    print(\"=== ANALYSE DES RATINGS ===\")",
    "    print(f\"Nombre total de ratings: {len(ratings):,}\")",
    "    print(f\"Nombre d'utilisateurs uniques: {ratings['userId'].nunique():,}\")",
    "    print(f\"Période: {pd.to_datetime(ratings['timestamp'], unit='s').min()} à {pd.to_datetime(ratings['timestamp'], unit='s').max()}\")",
    "    \n",
    "    # Statistiques des ratings\n",
    "    print(\"\\n=== STATISTIQUES DES RATINGS ===\")",
    "    print(ratings['rating'].describe())\n",
    "    \n",
    "    # Affichage des premières lignes\n",
    "    print(\"\\n=== APERÇU DES DONNÉES ===\")",
    "display(ratings.head(10))\n",
    "\n",
    "# Informations sur les types de données\n",
    "print(\"\\n=== INFORMATIONS SUR LES DONNÉES ===\")",
    "print(ratings.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution des ratings\n",
    "if data and 'ratings' in data:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Distribution des ratings\n",
    "    ratings['rating'].hist(bins=10, ax=axes[0,0], edgecolor='black')\n",
    "    axes[0,0].set_title('Distribution des Ratings')\n",
    "    axes[0,0].set_xlabel('Rating')\n",
    "    axes[0,0].set_ylabel('Fréquence')\n",
    "    \n",
    "    # Nombre de ratings par utilisateur\n",
    "    user_counts = ratings['userId'].value_counts()\n",
    "    user_counts.hist(bins=50, ax=axes[0,1], edgecolor='black')\n",
    "    axes[0,1].set_title('Distribution du Nombre de Ratings par Utilisateur')\n",
    "    axes[0,1].set_xlabel('Nombre de Ratings')\n",
    "    axes[0,1].set_ylabel('Nombre d\\'Utilisateurs')\n",
    "    axes[0,1].set_xscale('log')\n",
    "    axes[0,1].set_yscale('log')\n",
    "    \n",
    "    # Nombre de ratings par film\n",
    "    movie_counts = ratings['movieId'].value_counts()\n",
    "    movie_counts.hist(bins=50, ax=axes[1,0], edgecolor='black')\n",
    "    axes[1,0].set_title('Distribution du Nombre de Ratings par Film')\n",
    "    axes[1,0].set_xlabel('Nombre de Ratings')\n",
    "    axes[1,0].set_ylabel('Nombre de Films')\n",
    "    axes[1,0].set_xscale('log')\n",
    "    axes[1,0].set_yscale('log')\n",
    "    \n",
    "    # Évolution temporelle des ratings\n",
    "    ratings['date'] = pd.to_datetime(ratings['timestamp'], unit='s')\n",
    "    ratings['year'] = ratings['date'].dt.year\n",
    "    yearly_counts = ratings['year'].value_counts().sort_index()\n",
    "    yearly_counts.plot(ax=axes[1,1])\n",
    "    axes[1,1].set_title('Évolution du Nombre de Ratings par Année')\n",
    "    axes[1,1].set_xlabel('Année')\n",
    "    axes[1,1].set_ylabel('Nombre de Ratings')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploration des Films"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data and 'movies' in data:\n",
    "    movies = data['movies']\n",
    "    \n",
    "    print(\"=== ANALYSE DES FILMS ===)\n",
    "    print(f\"Nombre total de films: {len(movies):,}\")\n",
    "    \n",
    "    # Extraction de l'année depuis le titre\n",
    "    movies['year'] = movies['title'].str.extract(r'\\((\\d{4})\\)$')[0]\n",
    "    movies['year'] = pd.to_numeric(movies['year'], errors='coerce')\n",
    "    \n",
    "    # Nettoyage du titre\n",
    "    movies['clean_title'] = movies['title'].str.replace(r'\\s*\\(\\d{4}\\)$', '', regex=True)\n",
    "    \n",
    "    print(f\"Période des films: {movies['year'].min():.0f} à {movies['year'].max():.0f}\")\n",
    "    \n",
    "    # Affichage des premières lignes\n",
    "    print(\"\\n=== APERÇU DES FILMS ===)\n",
    "    display(movies.head(10))\n",
    "    \n",
    "    # Analyse des genres\n",
    "    print(\"\\n=== ANALYSE DES GENRES ===)\n",
    "    # Séparation des genres\n",
    "    all_genres = []\n",
    "    for genres in movies['genres'].dropna():\n",
    "        all_genres.extend(genres.split('|'))\n",
    "    \n",
    "    genre_counts = pd.Series(all_genres).value_counts()\n",
    "    print(f\"Nombre de genres uniques: {len(genre_counts)}\")\n",
    "    print(\"\\nTop 10 des genres:\")\n",
    "    print(genre_counts.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisations des films\n",
    "if data and 'movies' in data:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Distribution des années\n",
    "    movies['year'].hist(bins=30, ax=axes[0,0], edgecolor='black')\n",
    "    axes[0,0].set_title('Distribution des Films par Année')\n",
    "    axes[0,0].set_xlabel('Année')\n",
    "    axes[0,0].set_ylabel('Nombre de Films')\n",
    "    \n",
    "    # Top genres\n",
    "    genre_counts.head(15).plot(kind='barh', ax=axes[0,1])\n",
    "    axes[0,1].set_title('Top 15 des Genres')\n",
    "    axes[0,1].set_xlabel('Nombre de Films')\n",
    "    \n",
    "    # Évolution des genres dans le temps\n",
    "    top_genres = genre_counts.head(5).index\n",
    "    for genre in top_genres:\n",
    "        genre_by_year = []\n",
    "        years = sorted(movies['year'].dropna().unique())\n",
    "        for year in years:\n",
    "            year_movies = movies[movies['year'] == year]\n",
    "            genre_count = year_movies['genres'].str.contains(genre, na=False).sum()\n",
    "            genre_by_year.append(genre_count)\n",
    "        axes[1,0].plot(years, genre_by_year, label=genre, marker='o', markersize=2)\n",
    "    \n",
    "    axes[1,0].set_title('Évolution des Top 5 Genres dans le Temps')\n",
    "    axes[1,0].set_xlabel('Année')\n",
    "    axes[1,0].set_ylabel('Nombre de Films')\n",
    "    axes[1,0].legend()\n",
    "    \n",
    "    # Nombre de genres par film\n",
    "    movies['genre_count'] = movies['genres'].str.count('\\|') + 1\n",
    "    movies['genre_count'].hist(bins=10, ax=axes[1,1], edgecolor='black')\n",
    "    axes[1,1].set_title('Distribution du Nombre de Genres par Film')\n",
    "    axes[1,1].set_xlabel('Nombre de Genres')\n",
    "    axes[1,1].set_ylabel('Nombre de Films')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyse Croisée Ratings-Films"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fusion des données\n",
    "if data and 'ratings' in data and 'movies' in data:\n",
    "    # Fusion ratings et movies\n",
    "    ratings_movies = ratings.merge(movies, on='movieId', how='left')\n",
    "    \n",
    "    print(\"=== ANALYSE CROISÉE ===)\n",
    "    print(f\"Données fusionnées: {len(ratings_movies):,} ratings\")\n",
    "    \n",
    "    # Films les plus populaires\n",
    "    popular_movies = ratings_movies.groupby(['movieId', 'title']).agg({\n",
    "        'rating': ['count', 'mean']\n",
    "    }).round(2)\n",
    "    \n",
    "    popular_movies.columns = ['num_ratings', 'avg_rating']\n",
    "    popular_movies = popular_movies.reset_index()\n",
    "    \n",
    "    # Filtrer les films avec au moins 100 ratings\n",
    "    popular_movies_filtered = popular_movies[popular_movies['num_ratings'] >= 100]\n",
    "    \n",
    "    print(\"\\n=== TOP 10 FILMS LES PLUS POPULAIRES (>100 ratings) ===)\n",
    "    top_popular = popular_movies_filtered.nlargest(10, 'num_ratings')\n",
    "    display(top_popular)\n",
    "    \n",
    "    print(\"\\n=== TOP 10 FILMS LES MIEUX NOTÉS (>100 ratings) ===)\n",
    "    top_rated = popular_movies_filtered.nlargest(10, 'avg_rating')\n",
    "    display(top_rated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse par genre\n",
    "if data and 'ratings' in data and 'movies' in data:\n",
    "    # Analyse des ratings par genre\n",
    "    genre_ratings = []\n",
    "    \n",
    "    for idx, row in movies.iterrows():\n",
    "        if pd.notna(row['genres']):\n",
    "            genres = row['genres'].split('|')\n",
    "            movie_ratings = ratings[ratings['movieId'] == row['movieId']]['rating']\n",
    "            \n",
    "            for genre in genres:\n",
    "                for rating in movie_ratings:\n",
    "                    genre_ratings.append({'genre': genre, 'rating': rating})\n",
    "    \n",
    "    genre_ratings_df = pd.DataFrame(genre_ratings)\n",
    "    \n",
    "    # Statistiques par genre\n",
    "    genre_stats = genre_ratings_df.groupby('genre')['rating'].agg(['count', 'mean', 'std']).round(2)\n",
    "    genre_stats = genre_stats.sort_values('mean', ascending=False)\n",
    "    \n",
    "    print(\"=== STATISTIQUES PAR GENRE ===)\n",
    "    display(genre_stats.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisations avancées\n",
    "if data and 'ratings' in data and 'movies' in data:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Relation entre popularité et note moyenne\n",
    "    axes[0,0].scatter(popular_movies['num_ratings'], popular_movies['avg_rating'], alpha=0.6)\n",
    "    axes[0,0].set_xlabel('Nombre de Ratings')\n",
    "    axes[0,0].set_ylabel('Note Moyenne')\n",
    "    axes[0,0].set_title('Relation Popularité vs Note Moyenne')\n",
    "    axes[0,0].set_xscale('log')\n",
    "    \n",
    "    # Distribution des notes moyennes par genre (top 10)\n",
    "    top_genres_stats = genre_stats.head(10)\n",
    "    top_genres_stats['mean'].plot(kind='barh', ax=axes[0,1])\n",
    "    axes[0,1].set_title('Note Moyenne par Genre (Top 10)')\n",
    "    axes[0,1].set_xlabel('Note Moyenne')\n",
    "    \n",
    "    # Évolution des ratings dans le temps\n",
    "    monthly_ratings = ratings_movies.groupby(ratings_movies['date'].dt.to_period('M'))['rating'].mean()\n",
    "    monthly_ratings.plot(ax=axes[1,0])\n",
    "    axes[1,0].set_title('Évolution de la Note Moyenne dans le Temps')\n",
    "    axes[1,0].set_xlabel('Date')\n",
    "    axes[1,0].set_ylabel('Note Moyenne')\n",
    "    axes[1,0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Heatmap des ratings par heure et jour de la semaine\n",
    "    ratings_movies['hour'] = ratings_movies['date'].dt.hour\n",
    "    ratings_movies['day_of_week'] = ratings_movies['date'].dt.day_name()\n",
    "    \n",
    "    # Créer une heatmap simplifiée\n",
    "    hour_day_counts = ratings_movies.groupby(['day_of_week', 'hour']).size().unstack(fill_value=0)\n",
    "    \n",
    "    # Réorganiser les jours de la semaine\n",
    "    day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    hour_day_counts = hour_day_counts.reindex(day_order)\n",
    "    \n",
    "    im = axes[1,1].imshow(hour_day_counts.values, cmap='YlOrRd', aspect='auto')\n",
    "    axes[1,1].set_xticks(range(0, 24, 4))\n",
    "    axes[1,1].set_xticklabels(range(0, 24, 4))\n",
    "    axes[1,1].set_yticks(range(len(day_order)))\n",
    "    axes[1,1].set_yticklabels(day_order)\n",
    "    axes[1,1].set_title('Activité des Ratings par Heure et Jour')\n",
    "    axes[1,1].set_xlabel('Heure')\n",
    "    axes[1,1].set_ylabel('Jour de la Semaine')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyse de la Sparsité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse de la sparsité de la matrice utilisateur-film\n",
    "if data and 'ratings' in data:\n",
    "    n_users = ratings['userId'].nunique()\n",
    "    n_movies = ratings['movieId'].nunique()\n",
    "    n_ratings = len(ratings)\n",
    "    \n",
    "    # Calcul de la sparsité\n",
    "    total_possible_ratings = n_users * n_movies\n",
    "    sparsity = (1 - (n_ratings / total_possible_ratings)) * 100\n",
    "    \n",
    "    print(\"=== ANALYSE DE LA SPARSITÉ ===)\n",
    "    print(f\"Nombre d'utilisateurs: {n_users:,}\")\n",
    "    print(f\"Nombre de films: {n_movies:,}\")\n",
    "    print(f\"Nombre de ratings: {n_ratings:,}\")\n",
    "    print(f\"Ratings possibles: {total_possible_ratings:,}\")\n",
    "    print(f\"Sparsité: {sparsity:.2f}%\")\n",
    "    print(f\"Densité: {100-sparsity:.2f}%\")\n",
    "    \n",
    "    # Distribution des utilisateurs actifs\n",
    "    user_activity = ratings['userId'].value_counts()\n",
    "    \n",
    "    print(\"\\n=== ACTIVITÉ DES UTILISATEURS ===\"),\n",
    "    print(f\"Utilisateur le plus actif: {user_activity.max()} ratings\")\n",
    "    print(f\"Utilisateur le moins actif: {user_activity.min()} ratings\")\n",
    "    print(f\"Moyenne de ratings par utilisateur: {user_activity.mean():.1f}\")\n",
    "    print(f\"Médiane de ratings par utilisateur: {user_activity.median():.1f}\")\n",
    "    \n",
    "    # Distribution des films populaires\n",
    "    movie_popularity = ratings['movieId'].value_counts()\n",
    "    \n",
    "    print(\"\\n=== POPULARITÉ DES FILMS ===)\n",
    "    print(f\"Film le plus populaire: {movie_popularity.max()} ratings\")\n",
    "    print(f\"Film le moins populaire: {movie_popularity.min()} ratings\")\n",
    "    print(f\"Moyenne de ratings par film: {movie_popularity.mean():.1f}\")\n",
    "    print(f\"Médiane de ratings par film: {movie_popularity.median():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Recommandations pour le Système"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommandations basées sur l'analyse\n",
    "print(\"=== RECOMMANDATIONS POUR LE SYSTÈME ===)\n",
    "print()\n",
    "\n",
    "print(\"1. 📊 DONNÉES:\")\n",
    "if data and 'ratings' in data:\n",
    "    print(f\"   • Dataset volumineux: {len(ratings):,} ratings\")\n",
    "    print(f\"   • Sparsité élevée: {sparsity:.1f}% - nécessite des techniques robustes\")\n",
    "    print(f\"   • Période: {ratings_movies['year'].min():.0f}-{ratings_movies['year'].max():.0f} - données historiques riches\")\n",
    "\n",
    "print(\"\\n2. 🎯 APPROCHES RECOMMANDÉES:\")\n",
    "print(\"   • Filtrage collaboratif: Exploiter les similarités utilisateur-film\")\n",
    "print(\"   • Filtrage par contenu: Utiliser les genres et métadonnées\")\n",
    "print(\"   • Système hybride: Combiner les deux approches\")\n",
    "print(\"   • Factorisation matricielle: SVD, NMF pour gérer la sparsité\")\n",
    "\n",
    "print(\"\\n3. ⚠️ DÉFIS IDENTIFIÉS:\")\n",
    "print(\"   • Cold start: Nouveaux utilisateurs/films\")\n",
    "print(\"   • Sparsité: Peu d'interactions par utilisateur\")\n",
    "print(\"   • Scalabilité: Volume important de données\")\n",
    "print(\"   • Biais temporel: Évolution des préférences\")\n",
    "\n",
    "print(\"\\n4. 🛠️ TECHNIQUES À IMPLÉMENTER:\")\n",
    "print(\"   • SVD (Singular Value Decomposition)\")\n",
    "print(\"   • NMF (Non-negative Matrix Factorization)\")\n",
    "print(\"   • KNN (K-Nearest Neighbors)\")\n",
    "print(\"   • TF-IDF pour le contenu textuel\")\n",
    "print(\"   • Similarité cosinus\")\n",
    "\n",
    "print(\"\\n5. 📈 MÉTRIQUES D'ÉVALUATION:\")\n",
    "print(\"   • RMSE, MAE pour la précision\")\n",
    "print(\"   • Precision@K, Recall@K pour le ranking\")\n",
    "print(\"   • NDCG pour la qualité du classement\")\n",
    "print(\"   • Coverage, Diversity pour la variété\")\n",
    "\n",
    "print(\"\\n6. 🔧 OPTIMISATIONS:\")\n",
    "print(\"   • Filtrage des utilisateurs/films peu actifs\")\n",
    "print(\"   • Normalisation des ratings\")\n",
    "print(\"   • Validation temporelle\")\n",
    "print(\"   • Cache pour les recommandations fréquentes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Sauvegarde des Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde des statistiques importantes\n",
    "insights = {\n",
    "    'dataset_stats': {\n",
    "        'total_ratings': len(ratings) if data and 'ratings' in data else 0,\n",
    "        'unique_users': ratings['userId'].nunique() if data and 'ratings' in data else 0,\n",
    "        'unique_movies': ratings['movieId'].nunique() if data and 'ratings' in data else 0,\n",
    "        'sparsity_percent': sparsity if data and 'ratings' in data else 0,\n",
    "        'rating_range': [ratings['rating'].min(), ratings['rating'].max()] if data and 'ratings' in data else [0, 0],\n",
    "        'time_range': [str(ratings['date'].min()), str(ratings['date'].max())] if data and 'ratings' in data else ['', '']\n",
    "    },\n",
    "    'recommendations': {\n",
    "        'filtering_thresholds': {\n",
    "            'min_user_ratings': 20,\n",
    "            'min_movie_ratings': 10\n",
    "        },\n",
    "        'models_to_implement': ['SVD', 'NMF', 'KNN', 'Content-based', 'Hybrid'],\n",
    "        'evaluation_metrics': ['RMSE', 'MAE', 'Precision@K', 'Recall@K', 'NDCG@K']\n",
    "    },\n",
    "    'analysis_date': str(datetime.now())\n",
    "}\n",
    "\n",
    "# Sauvegarde\n",
    "import json\n",
    "\n",
    "with open('../data/processed/data_insights.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(insights, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"✅ Insights sauvegardés dans data/processed/data_insights.json\")\n",
    "print(\"\\n📋 RÉSUMÉ DE L'EXPLORATION:\")\n",
    "print(f\"   • {insights['dataset_stats']['total_ratings']:,} ratings analysés\")\n",
    "print(f\"   • {insights['dataset_stats']['unique_users']:,} utilisateurs uniques\")\n",
    "print(f\"   • {insights['dataset_stats']['unique_movies']:,} films uniques\")\n",
    "print(f\"   • Sparsité: {insights['dataset_stats']['sparsity_percent']:.1f}%\")\n",
    "print(\"   • Prêt pour la phase de modélisation! 🚀\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}